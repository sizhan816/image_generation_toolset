import os
import streamlit as st
import torch
import datetime
from PIL import Image
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import make_image_grid, load_image

st.set_page_config(
    page_title="é€šç”¨å›¾ç”Ÿå›¾",
    page_icon="ğŸ–¼ï¸",
    layout='wide',
    initial_sidebar_state='expanded',
)

DEFAULT_PROMPT = '''
'''.strip()

DEFAULT_NEGATIVE_PROMPT = '''
(low quality:1.3), (worst quality:1.3)
'''.strip()

# Add your custom text here, with smaller font size
st.markdown(
    "<B> ğŸ–¼ï¸é€šç”¨å›¾ç”Ÿå›¾ï¼Œæ ¹æ®æºå›¾ç”Ÿæˆæ–°å›¾</B>",
    unsafe_allow_html=True)

model_files = os.listdir('./models')

with st.sidebar:
    base_model = st.selectbox(
        "åŸºåº•æ¨¡å‹",
        model_files,
        0,
    )
    lora_path = st.text_input('loraè·¯å¾„:')
    use_cuda = st.checkbox('å¯ç”¨cuda', value=True)
    seed = st.sidebar.number_input(
            "å›¾åƒç”Ÿæˆç§å­", value=23, min_value=0, max_value=int(1e9)
    )
    denoising_strength = st.sidebar.slider(
        'é‡ç»˜å¼ºåº¦', 0.0, 1.0, 0.8, step=0.01
    )
    resize_scale = st.sidebar.number_input(
        "ç¼©æ”¾æ¯”ä¾‹", value=1.0, min_value=0.1, max_value=2.0
    )
    guidance_scale = st.slider(
        'æŒ‡å¯¼å› å­', 0.0, 20.0, 7.5, step=0.1
    )
    num_inference_steps = st.slider(
        'æ¨ç†æ­¥æ•°', 1, 150, 20, step=1
    )

    cols = st.columns(2)
    export_btn = cols[0]
    reset = cols[1].button("é‡ç½®å‚æ•°", use_container_width=True)
    if reset:
        base_model = model_files[0]
        lora_path = ''
        use_cuda = True
        seed = 23
        denoising_strength = 0.8
        resize_scale = 1.0
        guidance_scale = 7.5
        num_inference_steps = 20

prompt_cols = st.columns(2)
prompt = prompt_cols[0].text_area(
    label="è¾“å…¥æç¤ºè¯",
    height=80,
    value=DEFAULT_PROMPT,
)

negative_prompt = prompt_cols[1].text_area(
    label="è¾“å…¥åå‘æç¤ºè¯",
    height=80,
    value=DEFAULT_NEGATIVE_PROMPT,
)
uploaded_file = st.file_uploader("ä¸Šä¼ æºå›¾æ–‡ä»¶")

#@st.cache_data(ttl=3600)  
def get_pipeline():
    pipe = AutoPipelineForImage2Image.from_single_file(
        f"models/{base_model}",
        torch_dtype = torch.float16,
        original_config_file="configs",
        safety_checker = None
    )
    print(use_cuda)
    if use_cuda:
        pipe = pipe.to("cuda")
    else:
        pipe = pipe.to("cpu")

    if lora_path != "":
        pipe.load_lora_weights(lora_path)

    return pipe

def generate_img():
    pipe = get_pipeline()

    generator = None
    if use_cuda:
        generator = torch.Generator("cuda").manual_seed(seed)
    else:
        generator = torch.Generator("cpu").manual_seed(seed)
    
    input_pil_img = Image.open(uploaded_file)
    input_image = load_image(input_pil_img)

    width = int(resize_scale * input_image.width)
    height = int(resize_scale * input_image.height)
    # image 2 image generation
    image = pipe(
        prompt=prompt, 
        negative_prompt=negative_prompt,
        width=width,
        height=height,
        guidance_scale=guidance_scale,
        num_inference_steps=num_inference_steps,
        strength = denoising_strength,
        image = input_image,
        generator=generator
    ).images[0]

    # save result image
    os.makedirs(f".\\outputs\\img2img\\{datetime.datetime.now().strftime('%Y-%m-%d')}", exist_ok=True)
    output_path = f".\\outputs\\img2img\\{datetime.datetime.now().strftime('%Y-%m-%d')}\\{datetime.datetime.now().strftime('%H-%M-%S')}_{seed}.png"
    image.save(output_path)

    display_image = Image.open(output_path)

    result_cols = st.columns(2)
    display_width = min(int(resize_scale * input_image.width), 512)
    result_cols[0].image(input_image, caption='æºå›¾ç‰‡', width=display_width)
    result_cols[1].image(display_image, caption='ç”Ÿæˆçš„å›¾ç‰‡', width=display_width)


cols = st.columns(6)
gen_button = cols[5].button("ç”Ÿæˆ", use_container_width=True)
if gen_button:
    generate_img()

