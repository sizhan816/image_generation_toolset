import os
import streamlit as st
import torch
from diffusers import StableDiffusionPipeline
import datetime
from PIL import Image


st.set_page_config(
    page_title="é€šç”¨æ–‡ç”Ÿå›¾",
    page_icon="	ğŸ…°ï¸",
    layout='wide',
    initial_sidebar_state='expanded',
)

DEFAULT_PROMPT = '''
(cartoon),(best quality),(ultra-detailed),1boy, full body, chibi, yellow, outdoors, beret
'''.strip()

DEFAULT_NEGATIVE_PROMPT = '''
(low quality:1.3), (worst quality:1.3)
'''.strip()

# Add your custom text here, with smaller font size
st.markdown(
    "<B> ğŸ…°ï¸é€šç”¨æ–‡ç”Ÿå›¾ï¼Œç”±æ–‡å­—æè¿°ç”Ÿæˆå›¾ç‰‡, æ”¯æŒä¸­æ–‡æè¿°è‡ªåŠ¨ç¿»è¯‘å’Œæ ¹æ®ä¸»ä½“æ‰©å†™ï¼Œæ¯”åŸç”ŸSDæ›´è´´å¿ƒğŸ’–</B>",
    unsafe_allow_html=True)
do_translate = st.checkbox('å¯ç”¨æç¤ºè¯ç¿»è¯‘å’Œæ‰©å†™', value = False)

model_files = os.listdir('./models')

with st.sidebar:
    base_model = st.selectbox(
        "åŸºåº•æ¨¡å‹",
        model_files,
        0,
    )
    lora_path = st.text_input('loraè·¯å¾„:')
    use_cuda = st.checkbox('å¯ç”¨cuda', value = True)
    seed = st.sidebar.number_input(
            "å›¾åƒç”Ÿæˆç§å­", value=23, min_value=0, max_value=int(1e9)
    )
    width = st.sidebar.number_input(
        "å›¾åƒå®½åº¦:", value=512, min_value=64, max_value=2048
    )
    height = st.sidebar.number_input(
        "å›¾åƒé«˜åº¦:", value=512, min_value=64, max_value=2048
    )
    guidance_scale = st.slider(
        'æŒ‡å¯¼å› å­', 0.0, 20.0, 7.5, step=0.1
    )
    num_inference_steps = st.slider(
        'æ¨ç†æ­¥æ•°', 1, 150, 20, step=1
    )

    cols = st.columns(2)
    export_btn = cols[0]
    reset = cols[1].button("é‡ç½®å‚æ•°", use_container_width=True)
    if reset:
        base_model = model_files[0]
        lora_path = ''
        use_cuda = True
        seed = 23
        width = 512
        height = 512
        guidance_scale = 7.5
        num_inference_steps = 20

prompt_cols = st.columns(2)
prompt = prompt_cols[0].text_area(
    label="è¾“å…¥æç¤ºè¯",
    height=80,
    value=DEFAULT_PROMPT,
)

negative_prompt = prompt_cols[1].text_area(
    label="è¾“å…¥åå‘æç¤ºè¯",
    height=80,
    value=DEFAULT_NEGATIVE_PROMPT,
)


#@st.cache_data(ttl=3600)  
def get_pipeline():
    pipe = StableDiffusionPipeline.from_single_file(
        f"models/{base_model}",
        torch_dtype = torch.float16,
        original_config_file="configs/v2-inference.yaml",
        safety_checker = None
     )

    if use_cuda:
        pipe = pipe.to("cuda")
    else:
        pipe = pipe.to("cpu")

    if lora_path != "":
        pipe.load_lora_weights(lora_path)

    return pipe

def generate_img():
    pipe = get_pipeline()

    generator = None
    if use_cuda:
        generator = torch.Generator("cuda").manual_seed(seed)
    else:
        generator = torch.Generator("cpu").manual_seed(seed)
    
    translated_prompt, translated_negative_prompt = prompt, negative_prompt
    if do_translate:
        from prompt_translate import translator
        translated_prompt = translator.translate_img_generation_prompt(prompt)
        translated_negative_prompt = translator.translate_img_generation_negative_prompt(negative_prompt)
    
    # text 2 image generation
    image = pipe(
        prompt=translated_prompt, 
        negative_prompt=translated_negative_prompt,
        width=width,
        height=height,
        guidance_scale=guidance_scale,
        num_inference_steps=num_inference_steps,
        generator=generator
    ).images[0]

    # save result image
    os.makedirs(f".\\outputs\\text2img\\{datetime.datetime.now().strftime('%Y-%m-%d')}", exist_ok=True)
    output_path = f".\\outputs\\text2img\\{datetime.datetime.now().strftime('%Y-%m-%d')}\\{datetime.datetime.now().strftime('%H-%M-%S')}_{seed}.png"
    image.save(output_path)

    display_area = st.columns(2)
    display_image = Image.open(output_path)
    display_area[0].image(display_image, caption='ç”Ÿæˆçš„å›¾ç‰‡', width=min(width, 512))
    if do_translate:
        display_area[1].success(f"ç¿»è¯‘å’Œæ‰©å†™åçš„æç¤ºè¯: {translated_prompt}")
        display_area[1].success(f"ç¿»è¯‘åçš„åå‘æç¤ºè¯: {translated_negative_prompt}")
        
    

gen_btn_cols = st.columns(6)
# export_btn0, export_btn1, export_btn2, export_btn3, export_btn4 = cols[0], cols[1], cols[2], cols[3], cols[4]
gen_button = gen_btn_cols[5].button("ç”Ÿæˆ", use_container_width=True)
if gen_button:
    generate_img()


